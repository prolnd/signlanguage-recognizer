{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742200176.364873  321683 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742200176.370366  322293 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3.4-arch1.1), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 19.1.7, DRM 3.59, 6.13.1-arch2-1)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1742200176.394076  322281 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742200176.412666  322268 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742200176.425309  322275 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/prolnd/Documents/signlanguage-recognition/.venv/lib/python3.12/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Processing image: K2904.jpg\n",
      "Processing image: K2904.jpg\n",
      "Processing image: K2904.jpg\n",
      "Processing image: K2904.jpg\n",
      "Exiting loop\n",
      "Processing image: K499.jpg\n",
      "Exiting loop\n",
      "Processing image: K429.jpg\n",
      "Exiting loop\n",
      "Processing image: K221.jpg\n",
      "Exiting loop\n",
      "Processing image: K120.jpg\n",
      "Exiting loop\n",
      "Processing image: K200.jpg\n",
      "Exiting loop\n",
      "Processing image: K685.jpg\n",
      "Exiting loop\n",
      "Processing image: K2679.jpg\n",
      "No hand detected in K2679.jpg\n",
      "Exiting loop\n",
      "Processing image: K2112.jpg\n",
      "Exiting loop\n",
      "Processing image: K1228.jpg\n",
      "Exiting loop\n",
      "Processing image: K2075.jpg\n",
      "Exiting loop\n",
      "Processing image: K2490.jpg\n",
      "Exiting loop\n",
      "Processing image: K2655.jpg\n",
      "No hand detected in K2655.jpg\n",
      "Exiting loop\n",
      "Processing image: K1429.jpg\n",
      "Exiting loop\n",
      "Processing image: K1808.jpg\n",
      "Exiting loop\n",
      "Processing image: K394.jpg\n",
      "Exiting loop\n",
      "Processing image: K2867.jpg\n",
      "Exiting loop\n",
      "Processing image: K988.jpg\n",
      "Exiting loop\n",
      "Processing image: K318.jpg\n",
      "Exiting loop\n",
      "Processing image: K1188.jpg\n",
      "Exiting loop\n",
      "Processing image: K1504.jpg\n",
      "Exiting loop\n",
      "Processing image: K54.jpg\n",
      "Exiting loop\n",
      "Processing image: K662.jpg\n",
      "Exiting loop\n",
      "Processing image: K2284.jpg\n",
      "Exiting loop\n",
      "Processing image: K2166.jpg\n",
      "Exiting loop\n",
      "Processing image: K1208.jpg\n",
      "Exiting loop\n",
      "Processing image: K1299.jpg\n",
      "Exiting loop\n",
      "Processing image: K631.jpg\n",
      "Exiting loop\n",
      "Processing image: K3000.jpg\n",
      "Exiting loop\n",
      "Processing image: K1926.jpg\n",
      "Exiting loop\n",
      "Processing image: K1953.jpg\n",
      "Exiting loop\n",
      "Processing image: K1870.jpg\n",
      "Exiting loop\n",
      "Processing image: K2933.jpg\n",
      "Exiting loop\n",
      "Processing image: K1547.jpg\n",
      "Exiting loop\n",
      "Processing image: K1168.jpg\n",
      "Exiting loop\n",
      "Processing image: K2507.jpg\n",
      "No hand detected in K2507.jpg\n",
      "Exiting loop\n",
      "Processing image: K421.jpg\n",
      "Exiting loop\n",
      "Processing image: K2584.jpg\n",
      "No hand detected in K2584.jpg\n",
      "Exiting loop\n",
      "Processing image: K1998.jpg\n",
      "Exiting loop\n",
      "Processing image: K724.jpg\n",
      "Exiting loop\n",
      "Processing image: K537.jpg\n",
      "Exiting loop\n",
      "Processing image: K676.jpg\n",
      "Exiting loop\n",
      "Processing image: K648.jpg\n",
      "Processing image: K648.jpg\n",
      "Exiting loop\n",
      "Processing image: K1099.jpg\n",
      "Processing image: K1099.jpg\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize MediaPipe Hands detector\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.5)\n",
    "\n",
    "# Directory containing images\n",
    "image_dir = \"images/asl_alphabet_train/K\"\n",
    "print(os.path.isdir(image_dir))\n",
    "counter = 0\n",
    "if os.path.isdir(image_dir):\n",
    "    counter = 0  # Counter for images with landmarks\n",
    "\n",
    "    # Process each image in the folder\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        for i in range(10):\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            print(f\"Processing image: {image_file}\")\n",
    "\n",
    "            # Read the image\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Could not read {image_file}\")\n",
    "                continue\n",
    "\n",
    "            # Convert the image to RGB (required by MediaPipe)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Detect hand landmarks\n",
    "            results = hands.process(image_rgb)\n",
    "\n",
    "            # Check if landmarks are found\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    # Draw landmarks on the image\n",
    "                    mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                counter += 1  # Increment counter if landmarks are found\n",
    "            else:\n",
    "                print(f\"No hand detected in {image_file}\")\n",
    "\n",
    "            # Display the image with landmarks\n",
    "            cv2.imshow(\"Hand Landmarks\", image)\n",
    "\n",
    "            # Wait for user input: Press Enter to proceed, Esc to exit\n",
    "            key = cv2.waitKey(0)\n",
    "            if key == 27:  # Press 'Esc' to exit\n",
    "                print(\"Exiting loop\")\n",
    "                break\n",
    "\n",
    "    # Cleanup: Close OpenCV windows\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Total images with landmarks: {counter}\")\n",
    "\n",
    "# Close MediaPipe hands module\n",
    "hands.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
